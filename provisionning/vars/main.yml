---
# defaults file for all playbook
swap_file_state: absent

hadoop_user: hadoop
install_hadoop_dir: /hadoop

# https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz
install_hadoop_file: hadoop-3.4.1
install_hadoop_file_hash: "sha512:09cda6943625bc8e4307deca7a4df76d676a51aca1b9a0171938b793521dfe1ab5970fdb9a490bab34c12a2230ffdaed2992bad16458169ac51b281be1ab6741"
# https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz
install_spark_file: spark-3.5.4
install_spark_file_hash: "sha512:33b6a78c155213b779e2c0d1eb6842cd915e66d47e99dd96959a67aedbed7b5afa1e169fed7e07741f9b6fed7a38204cae7431bf9a93b95bb74f095cf9583cb6"
# https://dlcdn.apache.org/hive/hive-4.0.1/apache-hive-4.0.1-bin.tar.gz
install_hive_file: hive-4.0.1
install_hive_file_hash: "sha256:2bf988a1ed17437b1103e367939c25a13f64d36cf6d1c3bef8c3f319f0067619"

install_hadoop_dirname_unzip: "{{ install_hadoop_dir }}/{{ install_hadoop_file }}"
install_spark_dirname_unzip: "{{ install_hadoop_dir }}/{{ install_spark_file }}-bin-hadoop3"

install_hadoop_file_zip: "{{ install_hadoop_file }}.tar.gz"
install_spark_file_zip: "{{ install_spark_file }}-bin-hadoop3.tgz"

hdfs_namenodes: "{{ groups.namenodes }}"
yarn_resourcemanagers: "{{ groups.resourcemanagers }}"
hive_servers: "{{ groups.hiveservers }}"

hive_user: hive
postgresql_user: postgres
postgresql_data_dir: "/var/lib/pgsql/data"
postgresql_databases: [hive, data]
postgresql_users:
  - { db: hive, name: hive, password: "hive" }
  - { db: data, name: mpatron, password: "mpatron" }
  - { db: data, name: formation1, password: "demo" }
  - { db: data, name: formation2, password: "demo" }
  - { db: data, name: formation3, password: "demo" }
  - { db: data, name: formation4, password: "demo" }
  - { db: data, name: formation5, password: "demo" }
  - { db: data, name: formation6, password: "demo" }
  - { db: data, name: formation7, password: "demo" }
  - { db: data, name: formation8, password: "demo" }
  - { db: data, name: formation9, password: "demo" }
postgresql_schemas:
  - { db: hive, name: hive, owner: hive }
  - { db: data, name: mpatron, owner: mpatron }
postgresql_privs:
  - { db: data, roles: mpatron, privs: ALL, type: database }
  - { db: data, roles: formation1, privs: ALL, type: database }
  - { db: data, roles: formation2, privs: ALL, type: database }
  - { db: data, roles: formation3, privs: ALL, type: database }
  - { db: data, roles: formation4, privs: ALL, type: database }
  - { db: data, roles: formation5, privs: ALL, type: database }
  - { db: data, roles: formation6, privs: ALL, type: database }
  - { db: data, roles: formation7, privs: ALL, type: database }
  - { db: data, roles: formation8, privs: ALL, type: database }
  - { db: data, roles: formation9, privs: ALL, type: database }
hadoop_services:
  - "hadoop-datanode.service"
  - "hadoop-nodemanager.service"
  - "hadoop-namenode.service"
  - "hadoop-secondarynamenode.service"
  - "hadoop-resourcemanager.service"
user_name_to_delete:
  - hdfs
  - yarn
  - hadoop
file_or_directory_to_delete:
  - "{{ install_hadoop_dir }}/{{ install_hadoop_file }}"
  - "{{ install_hadoop_dir }}/disk/nn"
  - "{{ install_hadoop_dir }}/disk/sn"
  - "{{ install_hadoop_dir }}/disk/dn"
  - "{{ install_hadoop_dir }}/disk/tmp"
  - "{{ install_hadoop_dir }}/{{ install_spark_file }}-bin-hadoop3"
  - "{{ install_hadoop_dir }}/apache-{{ install_hive_file }}-bin"
  - /etc/profile.d/01-java-path.sh
  - /etc/profile.d/02-hadoop-path.sh
  - /etc/profile.d/03-spark-path.sh
  - /etc/systemd/system/hive-hiveserver2.service
  - /etc/systemd/system/hive-metastore.service
  - /etc/systemd/system/spark-history.service
  - /etc/systemd/system/hdfs.service
  - /etc/systemd/system/yarn.service
  - /etc/systemd/system/hadoop-datanode.service
  - /etc/systemd/system/hadoop-nodemanager.service
  - /etc/systemd/system/hadoop-namenode.service
  - /etc/systemd/system/hadoop-secondarynamenode.service
  - /etc/systemd/system/hadoop-resourcemanager.service
  - /etc/systemd/system/hadoop-yarn.service
  - /etc/systemd/system/hadoop-dfs.service
  - /var/lib/pgsql
